{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "motion_estimation_for_students.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWAYwUDrt3TC"
      },
      "source": [
        "# TP 2 : Computer Vision\n",
        "\n",
        "## Part 3 : motion estimation\n",
        "\n",
        "In this part of the TP, we are going to look at the following method for estimating motion :\n",
        "\n",
        "- block matching\n",
        "\n",
        "First, let us again load some packages and define some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u-GmtRWt3TF"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import numpy as np \n",
        "import imageio\n",
        "from skimage import color\n",
        "from scipy import signal\n",
        "from scipy.ndimage.morphology import binary_dilation\n",
        "\n",
        "is_colab = True\n",
        "\n",
        "def read_image(file_name):\n",
        "    img_color = imageio.imread(file_name)\n",
        "    img_gray = color.rgb2gray(img_color)\n",
        "    return img_gray,img_color\n",
        "    \n",
        "def write_image(img_in,file_name_out):\n",
        "    imageio.imwrite(file_name_out, np.uint8(255.0*img_in))\n",
        "    \n",
        "def display_image(img_in):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    if (img_in.ndim == 2):\n",
        "        plt.imshow(img_in,cmap='gray')\n",
        "    elif (img_in.ndim == 3):\n",
        "        # careful, in this case we supppose the pixel values are between 0 and 255\n",
        "        plt.imshow(np.uint8(img_in))\n",
        "    else:\n",
        "        print('Error, unknown number of dimensions in image')\n",
        "    return\n",
        "\n",
        "def display_motion(img_1,img_2,key_pts,motion,file_save=''):\n",
        "    \n",
        "    motion_x = motion[:,0]\n",
        "    motion_y = motion[:,1]\n",
        "    \n",
        "    img_size = img_1.shape\n",
        "    \n",
        "    head_width=2.0\n",
        "    head_length=3.0\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    ax = plt.imshow(img_1,cmap='gray')\n",
        "\n",
        "    print(key_pts.shape[0])\n",
        "    for i in range(0,key_pts.shape[0]):\n",
        "        x = key_pts[i,0]\n",
        "        y = key_pts[i,1]\n",
        "        plt.arrow(x,y, motion_x[i],motion_y[i] , color='r',\n",
        "            head_width=head_width, head_length=head_length,)\n",
        "    plt.gca().set_axis_off()\n",
        "    fig.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
        "                hspace = 0, wspace = 0)\n",
        "    plt.margins(0,0)\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.NullLocator())\n",
        "    plt.gca().yaxis.set_major_locator(mpl.ticker.NullLocator())\n",
        "\n",
        "    if (file_save != ''):\n",
        "        plt.savefig(file_save, bbox_inches = 'tight', pad_inches = 0)\n",
        "\n",
        "file_dir = 'images/'\n",
        "file_name_1 = 'afgrunden_1'\n",
        "file_name_2 = 'afgrunden_2'\n",
        "file_ext = '.png'\n",
        "\n",
        "if (is_colab == True):\n",
        "  !wget \"https://perso.telecom-paristech.fr/anewson/doc/images/afgrunden_1.png\"\n",
        "  !wget \"https://perso.telecom-paristech.fr/anewson/doc/images/afgrunden_2.png\"\n",
        "  img_1,_ = read_image(file_name_1+file_ext)\n",
        "  img_2,_ = read_image(file_name_2+file_ext)\n",
        "else:\n",
        "  img_1,_ = read_image(file_dir+file_name_1+file_ext)\n",
        "  img_2,_ = read_image(file_dir+file_name_2+file_ext)\n",
        "\n",
        "display_image(img_1)\n",
        "display_image(img_2)\n",
        "img_size = img_1.shape\n",
        "img_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D01qJh3Lt3TJ"
      },
      "source": [
        "__Question 3.1__ What sort of motion do you think is there between img_1 and img_2 ? You may want to flip between one image and another in an external viewer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0vw_sRGt3TK"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S_HxvnLt3TK"
      },
      "source": [
        "## Block matching\n",
        "\n",
        "Block matching is a very intuitive algorithm for motion estimation. We choose a patch size, and for each patch $\\Psi_p$ in the first frame, we look for the patch $\\Psi_q$ which is the most similar, in a certain region around the original position. The motion $(u,v)$ is then defined as $(u,v) = q-p$, such that : \n",
        "\n",
        "$\n",
        "\\begin{cases}\n",
        "q_x = p_x+u\\\\\n",
        "q_y = p_y+v\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "The ''similarity'' between two patches is the sum of squared differences (SSD) :\n",
        "\n",
        "$d(\\Psi_p,\\Psi_q) = \\sum_{i \\in \\mathcal{N}} \\left( I(p+i) - I(q+i) \\right)^2,$\n",
        "\n",
        "where $\\mathcal{N}$ is the patch neighbourhood (a square).\n",
        "\n",
        "We are going to be implementing block matching in a function called ``block_matching``. However, this can take a lot of time, so we only carry it out on a subset of the pixels, which we will call ``key_pts``. This will be a matrix of size $(N,2)$, where $N$ is the number of keypoints, and where each line has the following format :\n",
        "\n",
        "- $[x,y]$\n",
        "\n",
        "Create this function now, with the following parameters :\n",
        "\n",
        "- block_size = 7 (the patch size)\n",
        "- search_size = 15 (the maximum distance we search for the same patch in)\n",
        "\n",
        "You will have to deal with border conditions. There are two ways of doing this :\n",
        "\n",
        "- not allowing the patch search to go near to the borders (no closer than half the patch size)\n",
        "- making partial patch comparisons\n",
        "\n",
        "You can choose either method. The first is slightly easier to implement, but potentially incorrect near the borders. The second is more correct, but you have to make sure to make partial patch comparisons.\n",
        "\n",
        "Make sure you do __not__ carry out the patch distance with a loop (which would not be very optimal). You can first create the patch neighbourhood with\n",
        "\n",
        "- ``np.meshgrid``\n",
        "\n",
        "and then take the SSD of the two patches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "L2D2hbkrt3TM"
      },
      "source": [
        "def block_matching(img_1,img_2,key_pts):\n",
        "\n",
        "    motion = ... # FILL IN HERE. ``motion'' SHOULD BE A MATRIX OF SIZE [n_pts,2]\n",
        "\n",
        "    return motion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4-My598t3TN"
      },
      "source": [
        "We now draw some random keypoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sdP9YJIbt3TO"
      },
      "source": [
        "n_pts = 80\n",
        "key_pts = np.zeros((n_pts,2)).astype(int)\n",
        "# a random seed, if you want repeatability\n",
        "np.random.seed(10)\n",
        "\n",
        "pixel_list = np.asarray(range(0,img_size[0]*img_size[1]))\n",
        "np.random.shuffle(pixel_list)\n",
        "key_pts = np.zeros((n_pts,2)).astype(int)\n",
        "key_pts[:,1],key_pts[:,0] = np.unravel_index(pixel_list[0:n_pts],img_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnzeYgWBt3TO"
      },
      "source": [
        "key_pts[:,0].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kodh2TPUt3TP"
      },
      "source": [
        "Carry out the block matching and display the result with the ``display_motion`` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1lSnBjQat3TP"
      },
      "source": [
        "motion = ... # FILL IN HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ70TuEjt3TQ"
      },
      "source": [
        "display_motion(img_1,img_2,key_pts,motion)\n",
        "display_motion(img_1,img_2,key_pts,motion,file_name_1+'_motion_out.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMnh4A9Kt3TQ"
      },
      "source": [
        "__Question 3.2__ Does this look reasonable to you ? In what regions do you think the estimation might fail ? Does this visualisation confirm your hypothesis concerning the type of motion ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSIQNBzOt3TQ"
      },
      "source": [
        "__Answer__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucXVL9kvz4bv"
      },
      "source": [
        "__Question 3.3__ In this exercise, we used random points. What methods seen in the lesson could you use to choose better points. Explain why such points are better suited for the block matching algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5etWe1F0YKk"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcZwQWdwWD5c"
      },
      "source": [
        "__Question 3.4__ In this work, we have considered that each pixel/patch has its own, separate, local, motion. This is not the best model for the motion observed in these two images.\n",
        "\n",
        "What is a better motion model to use here? Why is this model better? Describe an algorithm to calculate such a motion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGn8XcKlZylg"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WzPW-kEEt3TR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}